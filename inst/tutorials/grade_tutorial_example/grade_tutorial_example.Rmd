---
title: "Downloadable Tutorial Example"
tutorial:
  id: "ex_02"
  version: 0.1
  
output:
  learnr::tutorial:
    progressive: false
    allow_skip: true
    css: ["css/nu-theme.css"]
runtime: shiny_prerendered
description: >
  This tutorial is for educators to demonstrate how to add ISDS functions for grading and downloading a tutorial.
---

```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
library(tutorialExtras)
library(palmerpenguins)
library(gradethis)

tutorial_options(
  exercise.timelimit = 10,
  exercise.diagnostics = FALSE
)

isds_setup(isds_exam = FALSE)

knitr::opts_chunk$set(echo = FALSE)
```


```{r, context = "server"}
grade_server("grade", 
             graded = c("Q-1", "Ex1"),
             graded_pts = c(3, 2),
             num_try = 3,
             deduction = 0.1)
```

```{r Name}
# student name
question_text("Name:",
              answer_fn(function(value){
                              if(length(value) >= 1 ) {
                                return(mark_as(TRUE))
                                }
                              return(mark_as(FALSE) )
                              }),
              correct = "Submitted",
              incorrect = "Submitted",
              allow_retry = FALSE)
```


````markdown
`r ''````{r}
grade_button_ui(id = "grade")
```
````

```{r}
grade_button_ui("grade")
```

## Introduction

The `tutorialExtras` package (Introduction to Statistics and Data Science) is designed to help customize `learnr` tutorials. It provides functions to... 

1. shuffle questions, randomly select questions, time submissions, prevent feedback until the tutorial is complete, and download an html grade report for submissions
1. grade tutorials, deduct points based on attempt, and download an html output for submissions.
1. create new question types such as `question_wordbank()`, `question_dropdown()`, and `question_blank()`

This tutorial demonstrates how to **grade tutorials, deduct points based on attempt, and download an html output for submissions.**

<br>

Thanks to the authors who developed the `learnr` (https://github.com/rstudio/learnr/) package which these functions are derived from.

Horst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/. doi:
10.5281/zenodo.3960218.


## Set up

In order to set up your tutorial you will want to include the `tutorialExtras` package and specify your desired settings in the `isds_setup()` function. By default, `isds_exam` is FALSE and `max_attempt` is set to Inf. If you do not need to change these settings then you do not need to load the function. You may want to also consider adding any desired learnr `tutorial_options()` and `gradethis_setup()` options from the `gradethis` package.

````markdown
`r ''```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
library(tutorialExtras)
library(gradethis)

# optional max_attempt arguement can be set in isds_setup()
# isds_setup(isds_exam = FALSE, 
#           max_attempt = Inf)
```
````

In a context = "server" code chunk you will need the `grade_server()` with an id that matches the `grade_print_ui()` and optional `grade_button_ui()`. In the `grade_server()` you have the option to specify the names of any questions or exercises with custom points and the number of submit attempts before a grade deduction. See Important Grading Tips for more details on grading.

````markdown
`r ''````{r, context = "server"}
grade_server(id = "grade", 
             graded = c("Q-1", "Ex1"),
             graded_pts = c(3, 2),
             num_try = 3,
             deduction = 0.1)
```
````

In this example, the Exercise with code chunk label "Ex1" is worth 2 points and the first question in the quiz from code chunk label "Q" is worth 3 points.


Somewhere in your exam tutorial you will need to include the `grade_print_ui()`. I recommend putting this buttons at the end of the tutorial in a section header "Submit". See the "Submit" section for an example of this setup.

I also recommend putting the `grade_button_ui()` somewhere in the tutorial. This will allow users to see their current progress in the tutorial. I will generally include this before any sections after a `Name` code chunk, so that it is easily clickable but it could also go in the "Submit" section.


## Exercise Example

The `palmerpenguins` dataset has been pre-loaded for you. Using the `penguins` dataset, fill in the blanks to construct a side-by-side boxplot of `flipper_length_mm` by `species`.

*Note: The below code chunk is named Ex1 with exercise = TRUE. There is also a corresponding Ex1-solution and Ex1-check code chunk to check the answer.*

```{r Ex1, exercise=TRUE}
ggplot(penguins, aes(x = species, y = ___)) +
  ___()
```


```{r Ex1-solution, exercise.reveal_solution = FALSE}
ggplot(penguins, aes(x = species, y = flipper_length_mm)) +
  geom_boxplot()
```

```{r Ex1-check, exercise.diagnostics = FALSE}
grade_this_code()
```


## Multiple Choice Questions

A few random quiz questions to help demonstrate grading features. In this setup, after 3 attempts a deduction of 10% will be made for that question. 

This could alternatively be put in an `exam()` function.

```{r Q}
quiz(
  caption = NULL,
  question_wordbank(paste("Using the penguins dataset, a linear regression model was run to predict body_mass_g based on flipper_length_mm and species. <br>", htmltools::img(src="images/penguins_lm.png", height = 100, width = 400)),
                    choices = c("What is the baseline/reference level?",
                                "Which species is predicted to on average have the lightest body mass?",
                                "Which species is predicted to on average have the heaviest body mass?"),
           wordbank = c("Adelie", "Gentoo", "Chinstrap"),
           answer(c("Adelie","Chinstrap","Gentoo"), correct = TRUE),
           box = 8,
           allow_retry = TRUE,
           random_answer_order = TRUE),
  question_dropdown("Which of the following is NOT an assumptions of linear models",
           answer("The response variable is normally distributed", correct = TRUE), 
           answer("The residuals are normally distributed"),
           answer("All the observed units are independent from each other."),
           answer("The relationship between the response variable and the predictors are linear"),
           allow_retry = TRUE,random_answer_order = TRUE),
  question("A lolly bag contains 2 red, 3 green and 2 blue gum balls. What is the probability of selecting a red or blue one?",
           answer("2/7"), 
           answer("5/7"),
           answer("4/7", correct = TRUE),
           answer("3/7"),
           allow_retry = TRUE,
           random_answer_order = TRUE)
)
```


## Important Grading Tips

Include a code chunk called "Name", ``{r Name}`, that includes a `question_text()` with `allow_retry = FALSE`, example shown below. This will ensure the user's name is on the downloaded tutorial! You can always set `exclude = c("Name")` in the `grade_server()` if you do not want it counted towards the points.

```{r, echo = TRUE, eval = FALSE}
question_text("Name:",
              answer_fn(function(value){
                              if(length(value) >= 1 ) {
                                return(mark_as(TRUE))
                                }
                              return(mark_as(FALSE) )
                              }),
              correct = "Submitted",
              incorrect = "Submitted",
              allow_retry = FALSE)
```

By default each question and exercise is worth 1 point. The amount of points a question/exercise is worth can be changed in the `grade_server()`. It is important to understand the naming convention of a question when specifying the `graded` option. If you have a `quiz()` or `exam()` with a set of questions, the label of the questions is the "chunkname-#". For example, if you name your code chunk "Q", ie: ``{r Q}`, then the first question is referenced by "Q-1" and the second question is "Q-2". If a question is not in a `quiz()` or `exam()`, then the label is simply the name of the code chunk. An exercise label is the name of the code chunk. 

If you "shuffle" an `exam()` you cannot reference the questions by "chunkname-#" as the order will be random for each user. Instead, within the question you can specify `options = list(label = "string")` and reference the question based on your defined label.

## Submit 

Once you are finished:

-   Click the "Download Grade" button to download an html grade.
-   Upload the html to your assessment platform (ie: Canvas).

````markdown
`r ''````{r}
grade_print_ui(id = "grade", label = "Download Grade")
```
````

```{r, echo = FALSE}
grade_print_ui("grade")
```

